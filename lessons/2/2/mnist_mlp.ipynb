{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, log_softmax=False):\n",
    "        super(Net, self).__init__()\n",
    "        innerLayerShape1 = 128\n",
    "        self.fc1 = nn.Linear(28*28, innerLayerShape1)\n",
    "        self.fc2 = nn.Linear(innerLayerShape1, 10)\n",
    "        self.log_softmax = log_softmax\n",
    "        self.optim = optim.SGD(self.parameters(), lr=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        if self.log_softmax:\n",
    "            x = F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            x = torch.log(F.softmax(x, dim=1))\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models):\n",
    "    train_loss = [0]*len(models)\n",
    "    train_loss_count = [0]*len(models)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for model in models:\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader))\n",
    "            lossesArr = []\n",
    "            for i, m in enumerate(models):\n",
    "                lossModel = m._loss.item()\n",
    "                train_loss[i] += lossModel\n",
    "                train_loss_count[i] += 1\n",
    "                lossesArr.append('{}: {:.6f}'.format(i, lossModel))\n",
    "            losses = ' '.join(lossesArr)\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader))\n",
    "        lossesArr = []\n",
    "        for i, m in enumerate(models):\n",
    "            lossModel = m._loss.item()\n",
    "            train_loss[i] += lossModel\n",
    "            train_loss_count[i] += 1\n",
    "            lossesArr.append('{}: {:.6f}'.format(i, lossModel))\n",
    "        losses = ' '.join(lossesArr)\n",
    "        print(line + losses)\n",
    "    for i in range(len(models)):\n",
    "        train_loss[i] /= train_loss_count[i]\n",
    "        print('Loss: {:.4f}'.format(train_loss[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Net(), Net(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, len(test_loader.dataset), p)\n",
    "line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "def test(models):\n",
    "    test_loss = [0]*len(models)\n",
    "    correct = [0]*len(models)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = [m(data) for m in models]\n",
    "            for i, m in enumerate(models):\n",
    "                test_loss[i] += m.loss(output[i], target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output[i].data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[i] += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        test_loss[i] /= len(test_loader.dataset)\n",
    "    correct_pct = [100. * c / len(test_loader.dataset) for c in correct]\n",
    "    lines = '\\n'.join([line(i, test_loss[i], correct[i], correct_pct[i]) for i in range(len(models))]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLosses 0: 2.357044 1: 2.333894\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLosses 0: 0.490137 1: 0.507116\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLosses 0: 0.370034 1: 0.356047\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLosses 0: 0.297172 1: 0.287763\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLosses 0: 0.338003 1: 0.341783\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLosses 0: 0.429378 1: 0.424008\n",
      "Train Epoch: 1 [60000/60000 (100%)]\tLosses 0: 0.356364 1: 0.363890\n",
      "Loss: 0.6626\n",
      "Loss: 0.6592\n",
      "Test set:\n",
      "0: Loss: 0.2606\tAccuracy: 9246/10000 (92%)\n",
      "1: Loss: 0.2606\tAccuracy: 9246/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLosses 0: 0.347097 1: 0.360936\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLosses 0: 0.269829 1: 0.274690\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLosses 0: 0.245149 1: 0.239770\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLosses 0: 0.131930 1: 0.121667\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLosses 0: 0.150505 1: 0.157685\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLosses 0: 0.355854 1: 0.351945\n",
      "Train Epoch: 2 [60000/60000 (100%)]\tLosses 0: 0.223164 1: 0.236295\n",
      "Loss: 0.2462\n",
      "Loss: 0.2490\n",
      "Test set:\n",
      "0: Loss: 0.1993\tAccuracy: 9421/10000 (94%)\n",
      "1: Loss: 0.2013\tAccuracy: 9419/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLosses 0: 0.274674 1: 0.297976\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLosses 0: 0.073968 1: 0.077743\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLosses 0: 0.073251 1: 0.072190\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLosses 0: 0.148743 1: 0.160332\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLosses 0: 0.191211 1: 0.186579\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLosses 0: 0.170453 1: 0.183603\n",
      "Train Epoch: 3 [60000/60000 (100%)]\tLosses 0: 0.157900 1: 0.171576\n",
      "Loss: 0.1557\n",
      "Loss: 0.1643\n",
      "Test set:\n",
      "0: Loss: 0.1630\tAccuracy: 9534/10000 (95%)\n",
      "1: Loss: 0.1650\tAccuracy: 9517/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLosses 0: 0.144854 1: 0.140623\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLosses 0: 0.091801 1: 0.099491\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLosses 0: 0.226250 1: 0.200737\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLosses 0: 0.164300 1: 0.172951\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLosses 0: 0.192148 1: 0.214389\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLosses 0: 0.221262 1: 0.209952\n",
      "Train Epoch: 4 [60000/60000 (100%)]\tLosses 0: 0.079119 1: 0.056522\n",
      "Loss: 0.1600\n",
      "Loss: 0.1564\n",
      "Test set:\n",
      "0: Loss: 0.1431\tAccuracy: 9587/10000 (96%)\n",
      "1: Loss: 0.1440\tAccuracy: 9580/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLosses 0: 0.203221 1: 0.202860\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLosses 0: 0.053736 1: 0.072408\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLosses 0: 0.145925 1: 0.137502\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLosses 0: 0.267715 1: 0.267588\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLosses 0: 0.237941 1: 0.231267\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLosses 0: 0.092383 1: 0.104747\n",
      "Train Epoch: 5 [60000/60000 (100%)]\tLosses 0: 0.032242 1: 0.034365\n",
      "Loss: 0.1476\n",
      "Loss: 0.1501\n",
      "Test set:\n",
      "0: Loss: 0.1264\tAccuracy: 9643/10000 (96%)\n",
      "1: Loss: 0.1280\tAccuracy: 9625/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLosses 0: 0.173421 1: 0.158598\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLosses 0: 0.165097 1: 0.188901\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLosses 0: 0.169230 1: 0.179875\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLosses 0: 0.304985 1: 0.266423\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLosses 0: 0.040400 1: 0.052132\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLosses 0: 0.276119 1: 0.263392\n",
      "Train Epoch: 6 [60000/60000 (100%)]\tLosses 0: 0.019645 1: 0.022138\n",
      "Loss: 0.1641\n",
      "Loss: 0.1616\n",
      "Test set:\n",
      "0: Loss: 0.1163\tAccuracy: 9672/10000 (97%)\n",
      "1: Loss: 0.1184\tAccuracy: 9650/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLosses 0: 0.084735 1: 0.071469\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLosses 0: 0.099531 1: 0.086388\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLosses 0: 0.165752 1: 0.178480\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLosses 0: 0.190193 1: 0.193625\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLosses 0: 0.073663 1: 0.061762\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLosses 0: 0.075047 1: 0.102528\n",
      "Train Epoch: 7 [60000/60000 (100%)]\tLosses 0: 0.209768 1: 0.230714\n",
      "Loss: 0.1284\n",
      "Loss: 0.1321\n",
      "Test set:\n",
      "0: Loss: 0.1086\tAccuracy: 9679/10000 (97%)\n",
      "1: Loss: 0.1114\tAccuracy: 9663/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLosses 0: 0.122620 1: 0.132372\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLosses 0: 0.123380 1: 0.149860\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLosses 0: 0.231461 1: 0.194789\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLosses 0: 0.048843 1: 0.058580\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLosses 0: 0.058379 1: 0.052536\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLosses 0: 0.068465 1: 0.072065\n",
      "Train Epoch: 8 [60000/60000 (100%)]\tLosses 0: 0.162826 1: 0.203106\n",
      "Loss: 0.1166\n",
      "Loss: 0.1233\n",
      "Test set:\n",
      "0: Loss: 0.1018\tAccuracy: 9712/10000 (97%)\n",
      "1: Loss: 0.1030\tAccuracy: 9675/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLosses 0: 0.029324 1: 0.033567\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLosses 0: 0.027770 1: 0.021874\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLosses 0: 0.134421 1: 0.130732\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLosses 0: 0.094033 1: 0.107276\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLosses 0: 0.041329 1: 0.039736\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch, models)\n",
    "    test(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
